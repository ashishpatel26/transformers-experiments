{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "natural-language-generation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0byTkrkMtbul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oaGoqqttnSn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "e4fbeafb-6e51-47b4-d925-d65ec44c7008"
      },
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "# add the EOS token as PAD token to avoid warnings\n",
        "model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id = tokenizer.eos_token_id)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint weights were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMu3e66auIuY",
        "colab_type": "text"
      },
      "source": [
        "### Greedy Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F96599SguKmh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "3be3759d-db76-456b-b927-adbf8dbe4243"
      },
      "source": [
        "# encode context the generation is conditioned on\n",
        "input_ids = tokenizer.encode('I enjoy walking with my cute dog', return_tensors = 'tf')\n",
        "\n",
        "# generate text until the output length (which includes the context length) reaches 50\n",
        "greedy_output = model.generate(input_ids, max_length = 50)\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(greedy_output[0], skip_special_tokens = True))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with my dog. I'm not sure if I'll ever be able to walk with my dog.\n",
            "\n",
            "I'm not sure if I'll\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0K9H84w2vF6B",
        "colab_type": "text"
      },
      "source": [
        "### Beam search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FYkQ56hvHYC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "861355d6-733d-4745-fb9b-141415393514"
      },
      "source": [
        "beam_output = model.generate(\n",
        "    input_ids,  \n",
        "    max_length = 50, \n",
        "    num_beams = 5, \n",
        "    early_stopping = True\n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(beam_output[0], skip_special_tokens = True))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n",
            "\n",
            "I'm not sure if I'll ever be able to walk with him again. I'm not sure if I'll\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xsn4WMu6vU0E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "64a8137f-62b7-49b9-c3fb-11e8e0e70c5d"
      },
      "source": [
        "# set no_repeat_ngram_size to 2 as repetition penalty\n",
        "beam_output = model.generate(\n",
        "    input_ids, \n",
        "    max_length = 50, \n",
        "    num_beams = 5, \n",
        "    no_repeat_ngram_size = 2, \n",
        "    early_stopping = True\n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(beam_output[0], skip_special_tokens = True))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n",
            "\n",
            "I've been thinking about this for a while now, and I think it's time for me to take a break\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzF_Saw1vpzb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "4a10aeff-a9d1-4494-c7dc-a5d87d33ae45"
      },
      "source": [
        "# set return_num_sequences > 1, assertion(num_return_sequences <= num_beams) as num_beams are all probs shown so sequences returned cannot be greater than all possible probs\n",
        "beam_outputs = model.generate(\n",
        "    input_ids, \n",
        "    max_length = 50, \n",
        "    num_beams = 5, \n",
        "    no_repeat_ngram_size = 2, \n",
        "    num_return_sequences = 5, \n",
        "    early_stopping = True\n",
        ")\n",
        "\n",
        "# now we have 3 output sequences\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "for i, beam_output in enumerate(beam_outputs):\n",
        "  print(\"{}: {}\".format(i, tokenizer.decode(beam_output, skip_special_tokens = True)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "0: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n",
            "\n",
            "I've been thinking about this for a while now, and I think it's time for me to take a break\n",
            "1: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n",
            "\n",
            "I've been thinking about this for a while now, and I think it's time for me to get back to\n",
            "2: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with her again.\n",
            "\n",
            "I've been thinking about this for a while now, and I think it's time for me to take a break\n",
            "3: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with her again.\n",
            "\n",
            "I've been thinking about this for a while now, and I think it's time for me to get back to\n",
            "4: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n",
            "\n",
            "I've been thinking about this for a while now, and I think it's time for me to take a step\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}