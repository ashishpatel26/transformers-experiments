{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "natural-language-generation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0byTkrkMtbul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oaGoqqttnSn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "70717b60-2601-4fd0-9757-3a92c2e72095"
      },
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "# add the EOS token as PAD token to avoid warnings\n",
        "model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id = tokenizer.eos_token_id)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All model checkpoint weights were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the weights of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMu3e66auIuY",
        "colab_type": "text"
      },
      "source": [
        "### Greedy Search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F96599SguKmh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "84a7aa43-8786-4a59-8d03-c2742c56b807"
      },
      "source": [
        "# encode context the generation is conditioned on\n",
        "input_ids = tokenizer.encode('I enjoy walking with my cute dog', return_tensors = 'tf')\n",
        "\n",
        "# generate text until the output length (which includes the context length) reaches 50\n",
        "greedy_output = model.generate(input_ids, max_length = 50)\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(greedy_output[0], skip_special_tokens = True))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with my dog. I'm not sure if I'll ever be able to walk with my dog.\n",
            "\n",
            "I'm not sure if I'll\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0K9H84w2vF6B",
        "colab_type": "text"
      },
      "source": [
        "### Beam search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FYkQ56hvHYC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "63cfdcec-bf00-495f-984b-f7adeffd88b9"
      },
      "source": [
        "beam_output = model.generate(\n",
        "    input_ids,  \n",
        "    max_length = 50, \n",
        "    num_beams = 5, \n",
        "    early_stopping = True\n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(beam_output[0], skip_special_tokens = True))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n",
            "\n",
            "I'm not sure if I'll ever be able to walk with him again. I'm not sure if I'll\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xsn4WMu6vU0E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "5d501f28-4d81-415e-c448-59d31e4709e3"
      },
      "source": [
        "# set no_repeat_ngram_size to 2 as repetition penalty\n",
        "beam_output = model.generate(\n",
        "    input_ids, \n",
        "    max_length = 50, \n",
        "    num_beams = 5, \n",
        "    no_repeat_ngram_size = 2, \n",
        "    early_stopping = True\n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(beam_output[0], skip_special_tokens = True))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n",
            "\n",
            "I've been thinking about this for a while now, and I think it's time for me to take a break\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzF_Saw1vpzb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "3cb26d86-8ce8-4c4c-ac8f-c42558d48414"
      },
      "source": [
        "# set return_num_sequences > 1, assertion(num_return_sequences <= num_beams) as num_beams are all probs shown so sequences returned cannot be greater than all possible probs\n",
        "beam_outputs = model.generate(\n",
        "    input_ids, \n",
        "    max_length = 50, \n",
        "    num_beams = 5, \n",
        "    no_repeat_ngram_size = 2, \n",
        "    num_return_sequences = 5, \n",
        "    early_stopping = True\n",
        ")\n",
        "\n",
        "# now we have 3 output sequences\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "for i, beam_output in enumerate(beam_outputs):\n",
        "  print(\"{}: {}\".format(i, tokenizer.decode(beam_output, skip_special_tokens = True)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "0: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n",
            "\n",
            "I've been thinking about this for a while now, and I think it's time for me to take a break\n",
            "1: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n",
            "\n",
            "I've been thinking about this for a while now, and I think it's time for me to get back to\n",
            "2: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with her again.\n",
            "\n",
            "I've been thinking about this for a while now, and I think it's time for me to take a break\n",
            "3: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with her again.\n",
            "\n",
            "I've been thinking about this for a while now, and I think it's time for me to get back to\n",
            "4: I enjoy walking with my cute dog, but I'm not sure if I'll ever be able to walk with him again.\n",
            "\n",
            "I've been thinking about this for a while now, and I think it's time for me to take a step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlDll87TykIX",
        "colab_type": "text"
      },
      "source": [
        "### Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_7SU_UPyogG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "2abe17a3-7e4d-4ddd-ef82-6df7a0c853eb"
      },
      "source": [
        "tf.random.set_seed(0)\n",
        "\n",
        "# activate sampling and deactivate top_k by setting top_k sampling to 0\n",
        "sample_output = model.generate(\n",
        "    input_ids, \n",
        "    do_sample = True, \n",
        "    max_length = 50, \n",
        "    top_k = 0\n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(sample_output[0], skip_special_tokens = True))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "I enjoy walking with my cute dog because of myself.\n",
            "\n",
            "Bryan: Oh, it's edgy.\n",
            "\n",
            "Rachel: Does your dog love weddings?\n",
            "\n",
            "Bryan: He won't, because he wants to\n",
            "\n",
            "Rachel:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaheFUZdyzA4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "f00d1eb3-02d2-410d-8da9-6e01a129ba8f"
      },
      "source": [
        "# use temperature to decrease the sensitivity to low probability candidates\n",
        "sample_output = model.generate(\n",
        "    input_ids, \n",
        "    do_sample = True, \n",
        "    max_length = 50, \n",
        "    top_k = 0, \n",
        "    temperature = 0.7\n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(sample_output[0], skip_special_tokens = True))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "I enjoy walking with my cute dog at the zoo, so I'm going to go out on a limb and say that I absolutely hate standing on my dog's back. But if you're not feeling just fine, it's an important first step toward\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0N0DXHCzCQJ",
        "colab_type": "text"
      },
      "source": [
        "### Top-K Sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b-7wM4izEeg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "b6de703c-515c-4f08-9650-e369c1394b21"
      },
      "source": [
        "# set top_k to 50\n",
        "sample_output = model.generate(\n",
        "    input_ids, \n",
        "    do_sample = True, \n",
        "    max_length = 50, \n",
        "    top_k = 50\n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(sample_output[0], skip_special_tokens = True))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "I enjoy walking with my cute dog and getting my water fountain ready, so I'm getting my dog in here about 11:00 am. We go to find some coffee, a cup of tea, a little cup of chocolate, some chocolate popcorn and\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLsH8Ax-zQVs",
        "colab_type": "text"
      },
      "source": [
        "### Top-p (nucleus) sampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0_XXfHSzRS6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "7f385f4d-2399-4ad5-9284-44ff99d494f2"
      },
      "source": [
        "# deactivate top_k sampling and sample only from 92% most likely words\n",
        "sample_output = model.generate(\n",
        "    input_ids, \n",
        "    do_sample = True, \n",
        "    max_length = 50, \n",
        "    top_p = 0.92, \n",
        "    top_k = 0\n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(sample_output[0], skip_special_tokens = True))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "I enjoy walking with my cute dog and I do love dancing. But I am not trying to kill anybody. I just want to get my loving dog back and I try hard to turn off him. He breaks me off. I want to protect my\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xbtsvIfzWYT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "d2a9ca92-e7fe-45e7-d16c-83a22f7dcfe0"
      },
      "source": [
        "# set top_k = 50 and set top_p = 0.95 and num_return_sequences = 3\n",
        "sample_outputs = model.generate(\n",
        "    input_ids,\n",
        "    do_sample=True, \n",
        "    max_length=50, \n",
        "    top_k=50, \n",
        "    top_p=0.95, \n",
        "    num_return_sequences=3\n",
        ")\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "for i, sample_output in enumerate(sample_outputs):\n",
        "  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "0: I enjoy walking with my cute dog and eating something amazing that I like. When they got home the first time they asked me where I would eat and I told them what I used to do back home. They said they were all really happy with their\n",
            "1: I enjoy walking with my cute dog and have a great time here at Wanda in downtown San Antonio.\"\n",
            "\n",
            "He added that it was a nice and quiet neighborhood that felt more welcoming than some of the other neighborhoods in the area.\n",
            "\n",
            "\"\n",
            "2: I enjoy walking with my cute dog, I like taking pictures, playing and I love to talk about them,\" she said.\n",
            "\n",
            "They also like to do things together, saying she enjoyed having her dog play outdoors at her home in Vancouver and wanted\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}