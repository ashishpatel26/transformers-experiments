{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "\n",
    "from transformers import (TFAutoModelWithLMHead, AutoTokenizer, \n",
    "    TFTrainer, TFTrainingArguments, TFT5ForConditionalGeneration, T5Config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0-dev20201029'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFT5(TFT5ForConditionalGeneration):\n",
    "    def __init__(self, *args, log_dir = None, cache_dir = None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.loss_tracker= tf.keras.metrics.Mean(name = 'loss') \n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        x, _= data\n",
    "        y = x[\"labels\"]\n",
    "        y = tf.reshape(y, [-1, 1])\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = self(x, training = True)\n",
    "            loss = outputs[0]\n",
    "            logits = outputs[1]\n",
    "            loss = tf.reduce_mean(loss)\n",
    "            \n",
    "            grads = tape.gradient(loss, self.trainable_variables)\n",
    "            \n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "        lr = self.optimizer._decayed_lr(tf.float32)\n",
    "        \n",
    "        self.loss_tracker.update_state(loss)        \n",
    "        self.compiled_metrics.update_state(y, logits)\n",
    "        metrics = {m.name: m.result() for m in self.metrics}\n",
    "        metrics.update({'lr': lr})\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, _ = data\n",
    "        y = x[\"labels\"]\n",
    "        y = tf.reshape(y, [-1, 1])\n",
    "        output = self(x, training = False)\n",
    "        loss = output[0]\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        logits = output[1]\n",
    "        \n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.compiled_metrics.update_state(y, logits)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:No config specified, defaulting to first: squad/v1.1\n",
      "INFO:absl:Load dataset info from /home/mirac13/tensorflow_datasets/squad/v1.1/2.0.0\n",
      "INFO:absl:Reusing dataset squad (/home/mirac13/tensorflow_datasets/squad/v1.1/2.0.0)\n",
      "INFO:absl:Constructing tf.data.Dataset for split train, from /home/mirac13/tensorflow_datasets/squad/v1.1/2.0.0\n",
      "INFO:absl:No config specified, defaulting to first: squad/v1.1\n",
      "INFO:absl:Load dataset info from /home/mirac13/tensorflow_datasets/squad/v1.1/2.0.0\n",
      "INFO:absl:Reusing dataset squad (/home/mirac13/tensorflow_datasets/squad/v1.1/2.0.0)\n",
      "INFO:absl:Constructing tf.data.Dataset for split validation, from /home/mirac13/tensorflow_datasets/squad/v1.1/2.0.0\n"
     ]
    }
   ],
   "source": [
    "train_dataset, info = tfds.load('squad', split = 'train', with_info = True)\n",
    "valid_dataset = tfds.load('squad', split = 'validation', with_info = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example data from the dataset: \n",
      " {'answers': {'answer_start': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([427], dtype=int32)>, 'text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'mobile phones'], dtype=object)>}, 'context': <tf.Tensor: shape=(), dtype=string, numpy=b'The difference in the above factors for the case of \\xce\\xb8=0 is the reason that most broadcasting (transmissions intended for the public) uses vertical polarization. For receivers near the ground, horizontally polarized transmissions suffer cancellation. For best reception the receiving antennas for these signals are likewise vertically polarized. In some applications where the receiving antenna must work in any position, as in mobile phones, the base station antennas use mixed polarization, such as linear polarization at an angle (with both vertical and horizontal components) or circular polarization.'>, 'id': <tf.Tensor: shape=(), dtype=string, numpy=b'57306bf68ab72b1400f9c4dc'>, 'question': <tf.Tensor: shape=(), dtype=string, numpy=b'What is one use that would require an antenna to receive signals in various ways at once?'>, 'title': <tf.Tensor: shape=(), dtype=string, numpy=b'Antenna_(radio)'>}\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(train_dataset))\n",
    "print(\"Example data from the dataset: \\n\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Steps:  21900\n",
      "Total Validation Steps:  2643\n"
     ]
    }
   ],
   "source": [
    "warmup_steps = 1e4\n",
    "batch_size = 4\n",
    "encoder_max_len = 250\n",
    "decoder_max_len = 54\n",
    "buffer_size = 1000\n",
    "ntrain = info.splits[\"train\"].num_examples\n",
    "nvalid = info.splits[\"validation\"].num_examples\n",
    "steps = int(np.ceil(ntrain/batch_size))\n",
    "valid_steps = int(np.ceil(nvalid/batch_size))\n",
    "print(\"Total Steps: \", steps)\n",
    "print(\"Total Validation Steps: \", valid_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(context,question ,answer, \n",
    "           encoder_max_len = encoder_max_len, decoder_max_len = decoder_max_len):\n",
    "    question_plus = f\"answer_me: {str(question.numpy().decode('utf-8'))}\"\n",
    "    question_plus += f\" context: {str(context.numpy().decode('utf-8'))}  </s>\"\n",
    "    \n",
    "    answer_plus = ', '.join([i.decode('utf-8') for i in list(answer.numpy())])\n",
    "    answer_plus = f\"{answer_plus} </s>\"\n",
    "    \n",
    "    encoder_inputs = tokenizer(question_plus, truncation=True, \n",
    "                               return_tensors = 'tf', max_length = encoder_max_len,\n",
    "                              padding = 'max_length')\n",
    "    \n",
    "    decoder_inputs = tokenizer(answer_plus, truncation = True, \n",
    "                               return_tensors = 'tf', max_length = decoder_max_len,\n",
    "                              padding = 'max_length')\n",
    "    \n",
    "    input_ids = encoder_inputs['input_ids'][0]\n",
    "    input_attention = encoder_inputs['attention_mask'][0]\n",
    "    target_ids = decoder_inputs['input_ids'][0]\n",
    "    target_attention = decoder_inputs['attention_mask'][0]\n",
    "    \n",
    "    return input_ids,input_attention, target_ids, target_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_tf(inputs):\n",
    "    context = inputs['context']\n",
    "    question = inputs['question']\n",
    "    answer = inputs['answers']['text']\n",
    "    encoded = tf.py_function(encode, [context, question, answer], \n",
    "                                           [tf.int32, tf.int32, tf.int32, tf.int32])\n",
    "    input_ids,input_attention, target_ids,target_attention = encoded\n",
    "    input_ids.set_shape([None])\n",
    "    target_ids.set_shape([None])\n",
    "    input_attention.set_shape([None])\n",
    "    target_attention.set_shape([None])\n",
    "    \n",
    "    data =  {'input_ids': input_ids, \n",
    "            'labels': target_ids, \n",
    "            'attention_mask': input_attention,\n",
    "           'decoder_attention_mask': target_attention}\n",
    "    return (data, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(source_dataset, cache_path = None, batch_size = 4, \n",
    "                   buffer_size = 1000, shuffling = True):\n",
    "    dataset = source_dataset.map(encode_tf, num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    if cache_path is not None:\n",
    "        dataset = dataset.cache(cache_path)        \n",
    "    if shuffling:\n",
    "        dataset = dataset.shuffle(buffer_size)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = create_dataset(train_dataset, batch_size = batch_size, \n",
    "                         shuffling = True, cache_path = None)\n",
    "valid_ds = create_dataset(valid_dataset, batch_size = batch_size, \n",
    "                         shuffling = False, cache_path = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mirac13/anaconda3/envs/tf2/lib/python3.8/site-packages/transformers/tokenization_t5.py:176: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'input_ids': <tf.Tensor: shape=(4, 250), dtype=int32, numpy=\n",
       "  array([[ 1525,   834,   526,    10,   262, 15420,    31,     7, 23907,\n",
       "           2854,  1775,    19,   859,   149,   186,    13,   165,   773,\n",
       "             16, 25101,    58,  2625,    10,    37, 23907,  2854,  1775,\n",
       "             44,   262, 15420,    19,     8,   163,    80,    16, 25101,\n",
       "             11,    65,     8,   508,  3620,     6,  1341,    12,     3,\n",
       "             23,    52,    52,  5883,   257,   685,   173,  2197,   114,\n",
       "            576,  3849,    17, 19516,  1391,    11, 18597,    29, 11638,\n",
       "           3026,     5,     1,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0],\n",
       "         [ 1525,   834,   526,    10,   363,  3392,     7,   130,  7513,\n",
       "            743,  6912,     7,    21,  7332,    58,  2625,    10,    37,\n",
       "            166,   360, 25105,  3392,     7,   130,  6912,     7,    21,\n",
       "           7332,     5,   611,     6,   227,   761,    72, 30899,    11,\n",
       "             16,  2169,    53,     3,     9, 31031,    53,  1948,     6,\n",
       "              3,     9,  3385, 25105,  2054,    47,     3,   179,    12,\n",
       "           9589,     3,     9,  1184,   189,  6623, 15710,  9111,     6,\n",
       "             11,   856, 25105, 19900,     7,  2348,     5,    37,  1184,\n",
       "            189,  6623, 15710,     7,   258, 10626,     3,     4,   288,\n",
       "          10462,  7800,    13,  1184,   189,   545,     6,     3,     9,\n",
       "          13063,    17,   152,     3,   935,    75,    35,  1208,   879,\n",
       "              6,    12,     3,    60, 11127,   159,    15,    11,   991,\n",
       "             70,  9102,     5,   216,  1340,   326,     8,  3385,  9102,\n",
       "             45,   165,  1247,    57,     3,    60,    18, 12585,  1184,\n",
       "            189,  6623, 15710, 25105, 15859,  4710,     5,    37,  3385,\n",
       "              7,   258,   541, 17025,     8,  1184,   189,  6623, 15710,\n",
       "              7,    16, 25105,  3392,    44,     8, 10141,    13,     8,\n",
       "             71,    15,  5339,     7, 11654,    11,   646,  1184,   189,\n",
       "            545,    28,  7598,     3,     9,  9111,  3701,  6684,  7485,\n",
       "             12,  3033,    80,     5,   242,     3,     9, 20141,   579,\n",
       "              8,  1453,    13,    70,   592,    12,     8, 15481,     3,\n",
       "              7,  4437, 16851,    11, 11041,   120,     6,    11,     8,\n",
       "           1184,   189,  6623, 15710,     7, 19557,    21,  3065,     5,\n",
       "              1,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0],\n",
       "         [ 1525,   834,   526,    10,  2645,  1192,     8,  3504,  2091,\n",
       "              3, 12926,  7969,    58,  2625,    10,   486,     8,   636,\n",
       "             13,  9145,     6,     3,     9,   372,   365,     8,  2843,\n",
       "             13,  3059, 12672,  7223,   876,    11,  1192,     3,     9,\n",
       "           1437,   338,     8,  6164,  1597, 30924,     7,  1446,    13,\n",
       "           9522,     7,     5,  2940,   166, 30924,  3375,  1218,    11,\n",
       "              8,   166,    16,     8,   296,     6,    47,  7763,    57,\n",
       "          23726,     6,    11,     3,     9,   511,   988,    47,  2012,\n",
       "            132,    16,  1186, 23652,     5,   611,     6,     8,  1437,\n",
       "            410,   143,   169,    13,  9522,     7,    12,  3806,   165,\n",
       "              3, 10124,     3,   157, 16223,  6702,  6772,  2032,     7,\n",
       "             11,    16,     8,  4558,   651,    12,   608,    11,  1431,\n",
       "             30,   165, 10224,  5253,  2594,     6,    78,    34,    47,\n",
       "             59,     8,   166,  1551, 30924,  1601,  1218,     5,   466,\n",
       "          13005,  1550,    12,     8,  3504,  2091,     3, 12926,  7969,\n",
       "             13, 23652,     6,  1192,    57,     8, 12800,  4889,    13,\n",
       "              8, 20474,   447,  4654,  2200, 26550,   297,    44,  3504,\n",
       "           2091,     5,     1,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0],\n",
       "         [ 1525,   834,   526,    10,   363,   410, 12774,    23,   302,\n",
       "             43,    12,  5712,    12,   103,    16,   455,    12,  1205,\n",
       "             58,  2625,    10,  7762,  3672,    23,   302,     6,  5563,\n",
       "          12774,    23,   302,   139,  1215,   699,    16,   220,  4834,\n",
       "           1517,   376,     6,   258,     6,   386,   477,    12,  9095,\n",
       "              5,   216,    47,  5563,   139,  4514,  1273,   297,    12,\n",
       "           5653,    32,    15,     9,     6,    16,  5791, 12614,   117,\n",
       "           5653,    32,    15,     9,    41, 11889,  3302,   137,   216,\n",
       "           1622,  2881,  6621,     6,   396,     6,     3,    99,     3,\n",
       "             88,   130,    12,  1845,     8,    71,  5288,  1102,    68,\n",
       "            130, 12191,     5,   216,  1622,   376,     6,  5071,     6,\n",
       "            874,  6189,  2161,    13,  2045,    96,   235,  4595,   112,\n",
       "           3991,   121,    68, 12774,    23,   302, 12191,   135,     6,\n",
       "           2145,     6,     3,    88,   429,   200,  2381,   135,    30,\n",
       "            112, 25888,     7,   117,    38,     3,    88,   410,    92,\n",
       "              3,     9,   114,   915,    45,     8,     3, 25569,     7,\n",
       "              7,     6,  2647,  7249,     8, 28110,   669,    12,   857,\n",
       "             16,  2144,     6,    11,    59,    12,   399,     7,    15,\n",
       "          15835,     8,  2345,    13,   601,     5,     3, 31108,     7,\n",
       "            130,   263,    12,  1175,     8,  6621,    16,    37,  2345,\n",
       "              6,    68, 12774,    23,   302,     3,    17, 13296,   135,\n",
       "             91,     5,  7762,  3672,    23,   302,   270,   413,   106,\n",
       "           1622,    21,   376,   365,     3,     9,  6926,  4879,    12,\n",
       "          14556,     6,   213,     6,    16,     3,     9,  2542,  4381,\n",
       "             57,    37,  7512,    15,    17,     6,     3,    88,  8197,\n",
       "            120,  1219,  7762,  3672,    23,   302,    24,    71,  6736,\n",
       "              9,     7,    23,   302,   141,   118,     3,     9,    75,\n",
       "          10073,  1054,    44,  9422, 11346,     6,     1]], dtype=int32)>,\n",
       "  'labels': <tf.Tensor: shape=(4, 54), dtype=int32, numpy=\n",
       "  array([[   80,     1,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [25105,  3392,     7,     1,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [12800,  4889,    13,     8, 20474,   447,  4654,  2200, 26550,\n",
       "            297,    44,  3504,  2091,     1,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [ 9095,    28,     8, 25214,     7,     1,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
       "        dtype=int32)>,\n",
       "  'attention_mask': <tf.Tensor: shape=(4, 250), dtype=int32, numpy=\n",
       "  array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>,\n",
       "  'decoder_attention_mask': <tf.Tensor: shape=(4, 54), dtype=int32, numpy=\n",
       "  array([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>},\n",
       " None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = next(iter(train_ds))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
