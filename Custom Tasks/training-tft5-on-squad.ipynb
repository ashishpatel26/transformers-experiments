{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "\n",
    "from transformers import (TFAutoModelWithLMHead, AutoTokenizer, \n",
    "    TFTrainer, TFTrainingArguments, TFT5ForConditionalGeneration, T5Config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.0-dev20201029'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFT5(TFT5ForConditionalGeneration):\n",
    "    def __init__(self, *args, log_dir = None, cache_dir = None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.loss_tracker= tf.keras.metrics.Mean(name = 'loss') \n",
    "    \n",
    "    @tf.function\n",
    "    def train_step(self, data):\n",
    "        x, _= data\n",
    "        y = x[\"labels\"]\n",
    "        y = tf.reshape(y, [-1, 1])\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = self(x, training = True)\n",
    "            loss = outputs[0]\n",
    "            logits = outputs[1]\n",
    "            loss = tf.reduce_mean(loss)\n",
    "            \n",
    "            grads = tape.gradient(loss, self.trainable_variables)\n",
    "            \n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "        lr = self.optimizer._decayed_lr(tf.float32)\n",
    "        \n",
    "        self.loss_tracker.update_state(loss)        \n",
    "        self.compiled_metrics.update_state(y, logits)\n",
    "        metrics = {m.name: m.result() for m in self.metrics}\n",
    "        metrics.update({'lr': lr})\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "    def test_step(self, data):\n",
    "        x, _ = data\n",
    "        y = x[\"labels\"]\n",
    "        y = tf.reshape(y, [-1, 1])\n",
    "        output = self(x, training = False)\n",
    "        loss = output[0]\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        logits = output[1]\n",
    "        \n",
    "        self.loss_tracker.update_state(loss)\n",
    "        self.compiled_metrics.update_state(y, logits)\n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:No config specified, defaulting to first: squad/v1.1\n",
      "INFO:absl:Load dataset info from /home/mirac13/tensorflow_datasets/squad/v1.1/2.0.0\n",
      "INFO:absl:Reusing dataset squad (/home/mirac13/tensorflow_datasets/squad/v1.1/2.0.0)\n",
      "INFO:absl:Constructing tf.data.Dataset for split train, from /home/mirac13/tensorflow_datasets/squad/v1.1/2.0.0\n",
      "INFO:absl:No config specified, defaulting to first: squad/v1.1\n",
      "INFO:absl:Load dataset info from /home/mirac13/tensorflow_datasets/squad/v1.1/2.0.0\n",
      "INFO:absl:Reusing dataset squad (/home/mirac13/tensorflow_datasets/squad/v1.1/2.0.0)\n",
      "INFO:absl:Constructing tf.data.Dataset for split validation, from /home/mirac13/tensorflow_datasets/squad/v1.1/2.0.0\n"
     ]
    }
   ],
   "source": [
    "train_dataset, info = tfds.load('squad', split = 'train', with_info = True)\n",
    "valid_dataset = tfds.load('squad', split = 'validation', with_info = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example data from the dataset: \n",
      " {'answers': {'answer_start': <tf.Tensor: shape=(1,), dtype=int32, numpy=array([427], dtype=int32)>, 'text': <tf.Tensor: shape=(1,), dtype=string, numpy=array([b'mobile phones'], dtype=object)>}, 'context': <tf.Tensor: shape=(), dtype=string, numpy=b'The difference in the above factors for the case of \\xce\\xb8=0 is the reason that most broadcasting (transmissions intended for the public) uses vertical polarization. For receivers near the ground, horizontally polarized transmissions suffer cancellation. For best reception the receiving antennas for these signals are likewise vertically polarized. In some applications where the receiving antenna must work in any position, as in mobile phones, the base station antennas use mixed polarization, such as linear polarization at an angle (with both vertical and horizontal components) or circular polarization.'>, 'id': <tf.Tensor: shape=(), dtype=string, numpy=b'57306bf68ab72b1400f9c4dc'>, 'question': <tf.Tensor: shape=(), dtype=string, numpy=b'What is one use that would require an antenna to receive signals in various ways at once?'>, 'title': <tf.Tensor: shape=(), dtype=string, numpy=b'Antenna_(radio)'>}\n"
     ]
    }
   ],
   "source": [
    "data = next(iter(train_dataset))\n",
    "print(\"Example data from the dataset: \\n\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Steps:  21900\n",
      "Total Validation Steps:  2643\n"
     ]
    }
   ],
   "source": [
    "warmup_steps = 1e4\n",
    "batch_size = 4\n",
    "encoder_max_len = 250\n",
    "decoder_max_len = 54\n",
    "buffer_size = 1000\n",
    "ntrain = info.splits[\"train\"].num_examples\n",
    "nvalid = info.splits[\"validation\"].num_examples\n",
    "steps = int(np.ceil(ntrain/batch_size))\n",
    "valid_steps = int(np.ceil(nvalid/batch_size))\n",
    "print(\"Total Steps: \", steps)\n",
    "print(\"Total Validation Steps: \", valid_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(context,question ,answer, \n",
    "           encoder_max_len = encoder_max_len, decoder_max_len = decoder_max_len):\n",
    "    question_plus = f\"answer_me: {str(question.numpy().decode('utf-8'))}\"\n",
    "    question_plus += f\" context: {str(context.numpy().decode('utf-8'))}  </s>\"\n",
    "    \n",
    "    answer_plus = ', '.join([i.decode('utf-8') for i in list(answer.numpy())])\n",
    "    answer_plus = f\"{answer_plus} </s>\"\n",
    "    \n",
    "    encoder_inputs = tokenizer(question_plus, truncation=True, \n",
    "                               return_tensors = 'tf', max_length = encoder_max_len,\n",
    "                              padding = 'max_length')\n",
    "    \n",
    "    decoder_inputs = tokenizer(answer_plus, truncation = True, \n",
    "                               return_tensors = 'tf', max_length = decoder_max_len,\n",
    "                              padding = 'max_length')\n",
    "    \n",
    "    input_ids = encoder_inputs['input_ids'][0]\n",
    "    input_attention = encoder_inputs['attention_mask'][0]\n",
    "    target_ids = decoder_inputs['input_ids'][0]\n",
    "    target_attention = decoder_inputs['attention_mask'][0]\n",
    "    \n",
    "    return input_ids,input_attention, target_ids, target_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_tf(inputs):\n",
    "    context = inputs['context']\n",
    "    question = inputs['question']\n",
    "    answer = inputs['answers']['text']\n",
    "    encoded = tf.py_function(encode, [context, question, answer], \n",
    "                                           [tf.int32, tf.int32, tf.int32, tf.int32])\n",
    "    input_ids,input_attention, target_ids,target_attention = encoded\n",
    "    input_ids.set_shape([None])\n",
    "    target_ids.set_shape([None])\n",
    "    input_attention.set_shape([None])\n",
    "    target_attention.set_shape([None])\n",
    "    \n",
    "    data =  {'input_ids': input_ids, \n",
    "            'labels': target_ids, \n",
    "            'attention_mask': input_attention,\n",
    "           'decoder_attention_mask': target_attention}\n",
    "    return (data, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(source_dataset, cache_path = None, batch_size = 4, \n",
    "                   buffer_size = 1000, shuffling = True):\n",
    "    dataset = source_dataset.map(encode_tf, num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
    "    \n",
    "    if cache_path is not None:\n",
    "        dataset = dataset.cache(cache_path)        \n",
    "    if shuffling:\n",
    "        dataset = dataset.shuffle(buffer_size)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = create_dataset(train_dataset, batch_size = batch_size, \n",
    "                         shuffling = True, cache_path = None)\n",
    "valid_ds = create_dataset(valid_dataset, batch_size = batch_size, \n",
    "                         shuffling = False, cache_path = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mirac13/anaconda3/envs/tf2/lib/python3.8/site-packages/transformers/tokenization_t5.py:176: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'input_ids': <tf.Tensor: shape=(4, 250), dtype=int32, numpy=\n",
       "  array([[ 1525,   834,   526,    10,   363,   605, 21305,    26,     3,\n",
       "              9,  7354,  6313,    16,     8,  1348,  2074,    16,  1524,\n",
       "             58,  2625,    10, 15993,  1524,    31,     7,  2074, 14833,\n",
       "          19983,   120,    16,     8,  4160,   227,     8,  5212,  1150,\n",
       "           1602,     6,    45,    46,  5861,  6734,    13,  4848,   948,\n",
       "            770,    16,   957,  3288,    12,   300,  4357,   927,   770,\n",
       "             16,     8,  6694,     7,     5,    37,  3218, 13897,    21,\n",
       "           1524,  2301, 26804,    12, 23354,     7,   235,  1123,    11,\n",
       "            332,   173,  7165,     6,    28,     8,  1524, 22314,  6347,\n",
       "            616,  2852,     3,     9,   992,    21, 26610,     6,   379,\n",
       "              8,  1072,  1208,   549,  3272,    89,   606,     5,   100,\n",
       "             47,     3, 12940,    91,    13,  1524,    31,     7,   664,\n",
       "             18,    77,  5045,     9,     7,    53,  1075,    38,     3,\n",
       "              9,   779,  1038,   981,  2050,   383,     8,  6694,     7,\n",
       "              5,    37, 29989, 29147,    47,  2012,    16,     8,  6694,\n",
       "              7,    12,  1822,  1524,   581,     3,    17,    23,    26,\n",
       "            138, 18787,     7,    45,     8,  1117,  3319,     5,     1,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0],\n",
       "         [ 1525,   834,   526,    10,    86,    84,   690,    47, 12345,\n",
       "           5777,   883,  2170,    58,  2625,    10, 12345,  5777,   883,\n",
       "             47,  2170,    16, 19500,    41,   189,    35,    16,  9652,\n",
       "             18,   566,   425,  1208,    61,    16,   957,  4305,     6,\n",
       "             12,  4548,  2214,    18,  4057,  1362,     5,   432,    13,\n",
       "          12345,  5777,   883,    31,     7, 22229,   130,  6692,     6,\n",
       "             68,     8,  5777,   883,   384, 12069,    12, 15026,     9,\n",
       "          14378,   274, 12345,    47,  2170,     6,    11,    78,     3,\n",
       "             88,  1204, 15026,   152, 27843,     5,   328,  7571,    48,\n",
       "             38,   294,    13,    70,  2779,    38,     7,  4133,  6105,\n",
       "              6,    59,    38,    46,  3893,    13,    20,   208,   670,\n",
       "           7750,     5, 12345,    31,     7,  2353,  6308, 15177,    51,\n",
       "           1106,  7291,  5777,   883,    47,     3,     9,  6297,    45,\n",
       "           1491,   107, 11658,    11,     3,     9,  2472,    13,   973,\n",
       "             44,     8, 19500,   636,     6,    11,  2039, 24244, 19447,\n",
       "             47,    13, 10221,    15, 10488,    11,   454,   425,  6855,\n",
       "          19991,     5,   621,     3, 12585,  1452,    16, 19500,     6,\n",
       "              8,  5777,  4660,   263,     3,     9,  3607,   569,  8147,\n",
       "             16,   584,  4731,     7,    15,  2710,    10,  6308, 15177,\n",
       "             51,  1106,  7291,  1632,     3,     9,  2397,    16,     8,\n",
       "            973,  1669,    13, 19500,    31,     7, 10215, 14343,    32,\n",
       "           7429,  8816,   350,  4100,   115,    40,    11,     6,   227,\n",
       "            350,  4100,   115,    40,    31,     7,  1687,    16,   507,\n",
       "           3916,     6,  6308,   808,   147,     8,   268,     5,    41,\n",
       "            329,   138, 11015,  1626,   509,  3225,  3187,    24,  8816,\n",
       "            350,  4100,   115,    40,    31,     7,   166,   564,    47,\n",
       "          13016,    51,  1106,     6,   227,    84, 12345,  1204,   112,\n",
       "           2214,   564,     5,  5777,   883,  2448,     1],\n",
       "         [ 1525,   834,   526,    10,   363,  1357,   410,     3,    88,\n",
       "            143,    24,     3, 12913,     8,  1543,    16,    46,  3332,\n",
       "             12,   143,   378,    72, 13503,   729,    15,  1162,     3,\n",
       "             58,  2625,    10,    37,  7345,  3385, 12187,     3,   104,\n",
       "            469,  7450,   120,  2650,     8,   938, 10241,  4070, 12187,\n",
       "              6,     3,     9,   564,    59,    16,   169,   383,   165,\n",
       "            293,    97,     3,   104,  1632,  5684,     3, 12913,    57,\n",
       "           6781,  1543,   227,     8,   489,   189,  2646,     6,   116,\n",
       "          26423,   216,  3738, 29705,    41,  6762,   305,  3072,     3,\n",
       "             18,  6687,  6982,  1500,    12,   143,  6781,     8, 21039,\n",
       "             31,     7,  2314,  1612,     5,     3, 22243,    45,   258,\n",
       "             30,     6,    68,   952,  2283,     6,     8,  3385,    11,\n",
       "           6781,  9757,   130,  9114, 17165,    26,   139,     3,     9,\n",
       "            712,  7186,   509,    18, 25139,   296,     5,  1875,     8,\n",
       "           6271,  1244,  4771,     8,  7345, 12187,    31,     7,  1988,\n",
       "             12,     8,  3385,  9837,    21,   633, 11653,     6,   227,\n",
       "          17384,   312,    32,  6289,     3, 31657,  7435,   109,    51,\n",
       "          11624,     6,     3,  1765,    13,     8,  4937,     7,     6,\n",
       "             38,     8,    96, 25139, 26423,   121,    30,   944,  1882,\n",
       "           8640,     6,    46,  1810,    84,  3725,  2237,    12,     8,\n",
       "           3239,    13,     8,  6679,  3385, 12187,     6,     8,  6271,\n",
       "           1244,   708,    12, 14499,     8,  4937,     7,    11,  1553,\n",
       "             12,  2401,    12,     8,  7345,  3385, 12187,     3,  6974,\n",
       "             38,     8, 12187,    13,     8,  6781,     7,    41,   196,\n",
       "             51,  4267,   440,     3,  4744,    15,   509,  2781,   137,\n",
       "              1,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0],\n",
       "         [ 1525,   834,   526,    10,   571,   186,   151,   410, 27318,\n",
       "           3356,    57,   507,  2596,    58,  2625,    10, 15139,    53,\n",
       "             12,  4285,     8, 24404,  2149,     6, 27318, 24281,    26,\n",
       "             27,   115,  4476,    11, 10126,   112,  4284,  6187,     8,\n",
       "           2671,    13,  6436,    16,   507, 15000,    37,  5093,    11,\n",
       "              8, 21076, 28495,    15,    26,    28,  2390,   380,     5,\n",
       "             37, 20936,    52,  1602,     3, 19054,  1296,   203,     6,\n",
       "           4466,    21,   165, 14506,     3, 19645, 18762, 28229,     6,\n",
       "             11, 27145,   920,    16,    46,     3, 26454,  6224,     5,\n",
       "          30979,    92,     3,    49,   413,  1054,    16,  2808,  1740,\n",
       "              6,    38,     8,  9652,    29,     7,  3759,   430,  3211,\n",
       "            581,     8,  2379,    16,   507, 12900, 27318, 17025,   135,\n",
       "             44,     8, 10141,    13,  3129,  5096,     6,  1028,  6065,\n",
       "             53,     8, 26729, 22922,  5147,   581,  1410,     5,   938,\n",
       "            507,  2596,     6, 27318,     3, 16718,   147,  2861,   770,\n",
       "            151,   640,    46, 21039,    24,   141,   103, 14484,    16,\n",
       "           1740,     6,    84,   141,    59, 16903,    48,   593,    13,\n",
       "           1827, 16690,   437,     8,   477,    13,     8,  3385, 12187,\n",
       "              5,   216,  6997,   112,  4519,  2637,   190,     3,     9,\n",
       "            939,    13, 15454,     7,    11,   384, 14936,     5,   216,\n",
       "            990,     3,     9,   126,     3,     9, 17149,  2935,    75,\n",
       "             63,    16,  1410,   298,     3,  3232,     8,  1205,    13,\n",
       "          17243,     7,   113,   141,   118,  5241,   139,  1215,   699,\n",
       "             57,     8, 12197,     5,     1,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0]], dtype=int32)>,\n",
       "  'labels': <tf.Tensor: shape=(4, 54), dtype=int32, numpy=\n",
       "  array([[    8,  5212,  1150,  1602,     1,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [19500,     1,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [ 1500,    12,   143,  6781,     8, 21039,    31,     7,  2314,\n",
       "           1612,     5,     1,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "         [  147,  2861,   770,     1,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0]],\n",
       "        dtype=int32)>,\n",
       "  'attention_mask': <tf.Tensor: shape=(4, 250), dtype=int32, numpy=\n",
       "  array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>,\n",
       "  'decoder_attention_mask': <tf.Tensor: shape=(4, 54), dtype=int32, numpy=\n",
       "  array([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>},\n",
       " None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = next(iter(train_ds))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, warmup_steps = 1e4):\n",
    "    super().__init__()\n",
    "\n",
    "    self.warmup_steps = tf.cast(warmup_steps, tf.float32)\n",
    "    \n",
    "  def __call__(self, step):\n",
    "    step = tf.cast(step, tf.float32)\n",
    "    m = tf.maximum(self.warmup_steps, step)\n",
    "    m = tf.cast(m, tf.float32)\n",
    "    lr = tf.math.rsqrt(m)\n",
    "    \n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Learning rate')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('ggplot')\n",
    "schedule = CustomSchedule()\n",
    "plt.plot(schedule(tf.range(25000, dtype = tf.float32)))\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Learning rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor = \"val_accuracy\", patience = 2, restore_best_weights = True\n",
    ")\n",
    "\n",
    "callbacks = [early_stopping] \n",
    "metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(name = 'accuracy') ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFT5.\n",
      "\n",
      "All the layers of TFT5 were initialized from the model checkpoint at t5-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5 for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = TFT5.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = optimizer, metrics = metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mirac13/anaconda3/envs/tf2/lib/python3.8/site-packages/transformers/tokenization_t5.py:176: UserWarning: This sequence already has </s>. In future versions this behavior may lead to duplicated eos tokens being added.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21900/21900 [==============================] - 2729s 124ms/step - accuracy: 0.9209 - loss: 0.7446 - lr: 0.0089 - val_accuracy: 0.7467 - val_loss: 2.2704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f50f05fe850>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs_done = 0\n",
    "model.fit(train_ds, epochs = 1, steps_per_epoch = steps, callbacks = callbacks, \n",
    "          validation_data = valid_ds, validation_steps = valid_steps, initial_epoch = epochs_done)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"We went on a trip to Europe. We had our breakfast at 7 am in the morning at \\\n",
    "the nearby coffee shop. Wore a dark blue over coat for our first visit to Louvre Museum \\\n",
    "to experience history and art.\"\"\"\n",
    "\n",
    "question = \"At what time did we had breakfast?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  a\n"
     ]
    }
   ],
   "source": [
    "input_text =  f\"answer_me: {question} context: {context} </s>\"\n",
    "encoded_query = tokenizer(input_text, \n",
    "                         return_tensors = 'tf', padding = True, truncation = True)\n",
    "input_ids = encoded_query[\"input_ids\"]\n",
    "attention_mask = encoded_query[\"attention_mask\"]\n",
    "generated_answer = model.generate(input_ids, attention_mask = attention_mask, \n",
    "                                 max_length = decoder_max_len, top_p = 0.98, top_k = 50)\n",
    "decoded_answer = tokenizer.decode(generated_answer.numpy()[0])\n",
    "print(\"Answer: \", decoded_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
