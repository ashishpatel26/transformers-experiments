{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FineTune GPT-2 Chatbot.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpDpr45cS1CZ"
      },
      "source": [
        "!pip -q install transformers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WWahpGGS3_f"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import glob\n",
        "import torch\n",
        "import shutil\n",
        "import pickle\n",
        "import random\n",
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "from typing import Dict, List, Tuple\n",
        "from tqdm.notebook import tqdm, trange\n",
        "from statistics import mean, median, stdev\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
        "\n",
        "from transformers import (\n",
        "    MODEL_WITH_LM_HEAD_MAPPING,\n",
        "    WEIGHTS_NAME,\n",
        "    AdamW,\n",
        "    AutoConfig,\n",
        "    AutoModelWithLMHead,\n",
        "    AutoTokenizer,\n",
        "    PreTrainedModel,\n",
        "    PreTrainedTokenizer,\n",
        "    get_linear_schedule_with_warmup,\n",
        ")\n",
        "\n",
        "try:\n",
        "    from torch.utils.tensorboard import SummaryWriter\n",
        "except ImportError:\n",
        "    from tensorboardX import SummaryWriter"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTm4tS2_TU3f"
      },
      "source": [
        "# Configs\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "MODEL_CONFIG_CLASSES = list(MODEL_WITH_LM_HEAD_MAPPING.keys())\n",
        "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnFRxBmOTzLN"
      },
      "source": [
        "class Args():\n",
        "    def __init__(self):\n",
        "        self.output_dir = 'output'\n",
        "        self.model_type = 'gpt2'\n",
        "        self.model_name_or_path = 'microsoft/DialoGPT-small'\n",
        "        self.config_name = 'microsoft/DialoGPT-small'\n",
        "        self.tokenizer_name = 'microsoft/DialoGPT-small'\n",
        "        self.cache_dir = 'cached'\n",
        "        self.block_size = 512\n",
        "        self.do_train = True\n",
        "        self.do_eval = True\n",
        "        self.evaluate_during_training = False\n",
        "        self.per_gpu_train_batch_size = 4\n",
        "        self.per_gpu_eval_batch_size = 4\n",
        "        self.gradient_accumulation_steps = 1\n",
        "        self.learning_rate = 5e-5\n",
        "        self.weight_decay = 0.0\n",
        "        self.adam_epsilon = 1e-8\n",
        "        self.max_grad_norm = 1.0\n",
        "        self.num_train_epochs = 3\n",
        "        self.max_steps = -1\n",
        "        self.warmup_steps = 0\n",
        "        self.logging_steps = 1000\n",
        "        self.save_steps = 3500\n",
        "        self.save_total_limit = None\n",
        "        self.eval_all_checkpoints = False\n",
        "        self.no_cuda = False\n",
        "        self.overwrite_output_dir = True\n",
        "        self.overwrite_cache = True\n",
        "        self.should_continue = False\n",
        "        self.seed = 42\n",
        "        self.local_rank = -1\n",
        "        self.fp16 = False\n",
        "        self.fp16_opt_level = 'O1'\n",
        "\n",
        "args = Args()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1GYvzgkUBsl"
      },
      "source": [
        "### Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMvyvaznUDBk",
        "outputId": "bc571008-15fd-404c-ac83-a914ad966d89"
      },
      "source": [
        "! gdown https://drive.google.com/uc?id=1Lp-diuMohUTGyB9BSTFgeGZyY3dkNuEg"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Lp-diuMohUTGyB9BSTFgeGZyY3dkNuEg\n",
            "To: /content/final_es_conv.csv\n",
            "20.3MB [00:00, 64.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "DXGyIIsMUFOk",
        "outputId": "90c9f771-bc65-4f93-f63a-60d1cd7a0e3e"
      },
      "source": [
        "df = pd.read_csv('final_es_conv.csv')\n",
        "df = df.dropna()\n",
        "trn_df, val_df = train_test_split(df, test_size = 0.2)\n",
        "trn_df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>response</th>\n",
              "      <th>context</th>\n",
              "      <th>context/0</th>\n",
              "      <th>context/1</th>\n",
              "      <th>context/2</th>\n",
              "      <th>context/3</th>\n",
              "      <th>context/4</th>\n",
              "      <th>context/5</th>\n",
              "      <th>context/6</th>\n",
              "      <th>context/7</th>\n",
              "      <th>context/8</th>\n",
              "      <th>context/9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>40223</th>\n",
              "      <td>¿Lo cree?</td>\n",
              "      <td>¿Lo cree?</td>\n",
              "      <td>¿Ud. cree que Leonard Vole es inocente?</td>\n",
              "      <td>Déjeme preguntarle una cosa.</td>\n",
              "      <td>Lo cierto es que no tengo nada.</td>\n",
              "      <td>No tengo mucho con qué continuar, ¿verdad?</td>\n",
              "      <td>Nosotros de un lado y todas las probabilidades...</td>\n",
              "      <td>La carga de la caballería ligera o uno de esos...</td>\n",
              "      <td>Llevar este caso será cómo :</td>\n",
              "      <td>La acusación acabará con ella en cuanto la sub...</td>\n",
              "      <td>La mujer busca algo, ¿pero qué?</td>\n",
              "      <td>¿Quiere acompañarme a oler esas sales?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42067</th>\n",
              "      <td>¡Condición Roja!</td>\n",
              "      <td>¡Alarma Roja!</td>\n",
              "      <td>¡Condición Roja!</td>\n",
              "      <td>¡Operaciones, habla el Coronel Parkman!</td>\n",
              "      <td>¡Sí, señor!</td>\n",
              "      <td>¡Oprima el Botón de Alerta!</td>\n",
              "      <td>Bueno, se debe a que la vibración de... un son...</td>\n",
              "      <td>Usted sabe cómo los escaladores de montañas le...</td>\n",
              "      <td>Oh, cualquier clase de vibraciones inusuales.</td>\n",
              "      <td>Bueno, ¿y que pudo liberarla después de todo e...</td>\n",
              "      <td>Pudo haber estado encerrada en una prisión... ...</td>\n",
              "      <td>¿Quién puede estar seguro?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43758</th>\n",
              "      <td>Y ahora date prisa y decir adiós.</td>\n",
              "      <td>Estoy seguro de ello.</td>\n",
              "      <td>¿Lo crees así?</td>\n",
              "      <td>Estoy convencido de que va a encontrar un prof...</td>\n",
              "      <td>Ahora que hablo portugués, tengo que aprender ...</td>\n",
              "      <td>Tan pronto como supe húngaro, fuimos a Madeira.</td>\n",
              "      <td>Pero, mayor!</td>\n",
              "      <td>Condesa, por favor, sabes que adoro nuestra Em...</td>\n",
              "      <td>Para Grecia?</td>\n",
              "      <td>Para Grecia.</td>\n",
              "      <td>Pero, ¿dónde?</td>\n",
              "      <td>¿Otra vez?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20337</th>\n",
              "      <td>Catherine.</td>\n",
              "      <td>Catherine.</td>\n",
              "      <td>El bombardeo parece que ha terminado.</td>\n",
              "      <td>Si no le importa, me gustaría irme.</td>\n",
              "      <td>Será mejor que te calces, antes de que se te e...</td>\n",
              "      <td>La arquitectura es el arte más antiguo del mundo.</td>\n",
              "      <td>En resumen, querida...</td>\n",
              "      <td>La misma palabra indica la íntima unión de est...</td>\n",
              "      <td>Arquitectura.</td>\n",
              "      <td>Arco.</td>\n",
              "      <td>El arco, querida, puede que sea el elemento ar...</td>\n",
              "      <td>Esto, querida, se llama arco.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12886</th>\n",
              "      <td>iDudo que sepáis lo que es eso!</td>\n",
              "      <td>Tal vez esta sea nuestra idea de la decencia.</td>\n",
              "      <td>No como vosotros, que sólo queréis burlaros de...</td>\n",
              "      <td>Por lo menos era decente.</td>\n",
              "      <td>Sabía cómo manejar a la gente.</td>\n",
              "      <td>Menos a Okayo.</td>\n",
              "      <td>Conocía bien la gente.</td>\n",
              "      <td>Era muy amable y lo sabía todo.</td>\n",
              "      <td>Pues sí, yo quería al anciano.</td>\n",
              "      <td>Para Osen fue amor a primer a vista.</td>\n",
              "      <td>Además, era muy agudo.</td>\n",
              "      <td>Tienes razón.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                response  ...                               context/9\n",
              "40223                          ¿Lo cree?  ...  ¿Quiere acompañarme a oler esas sales?\n",
              "42067                   ¡Condición Roja!  ...              ¿Quién puede estar seguro?\n",
              "43758  Y ahora date prisa y decir adiós.  ...                              ¿Otra vez?\n",
              "20337                         Catherine.  ...           Esto, querida, se llama arco.\n",
              "12886    iDudo que sepáis lo que es eso!  ...                           Tienes razón.\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    }
  ]
}