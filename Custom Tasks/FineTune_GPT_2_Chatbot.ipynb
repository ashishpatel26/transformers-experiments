{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FineTune GPT-2 Chatbot.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpDpr45cS1CZ",
        "outputId": "0e463d49-5e0a-43e4-e688-a5a5ce1c61b5"
      },
      "source": [
        "!pip -q install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.4MB 13.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 44.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.9MB 54.1MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WWahpGGS3_f"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import glob\n",
        "import torch\n",
        "import shutil\n",
        "import pickle\n",
        "import random\n",
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple\n",
        "from tqdm.notebook import tqdm, trange\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "from torch.utils.data import DataLoader, Dataset, RandomSampler, SequentialSampler\n",
        "\n",
        "from transformers import (\n",
        "    MODEL_WITH_LM_HEAD_MAPPING,\n",
        "    WEIGHTS_NAME,\n",
        "    AdamW,\n",
        "    AutoConfig,\n",
        "    AutoModelWithLMHead,\n",
        "    AutoTokenizer,\n",
        "    PreTrainedModel,\n",
        "    PreTrainedTokenizer,\n",
        "    get_linear_schedule_with_warmup,\n",
        ")\n",
        "\n",
        "try:\n",
        "    from torch.utils.tensorboard import SummaryWriter\n",
        "except ImportError:\n",
        "    from tensorboardX import SummaryWriter"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTm4tS2_TU3f"
      },
      "source": [
        "# Configs\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "MODEL_CONFIG_CLASSES = list(MODEL_WITH_LM_HEAD_MAPPING.keys())\n",
        "MODEL_TYPES = tuple(conf.model_type for conf in MODEL_CONFIG_CLASSES)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnFRxBmOTzLN"
      },
      "source": [
        "class Args():\n",
        "    def __init__(self):\n",
        "        self.output_dir = 'output'\n",
        "        self.model_type = 'gpt2'\n",
        "        self.model_name_or_path = 'microsoft/DialoGPT-small'\n",
        "        self.config_name = 'microsoft/DialoGPT-small'\n",
        "        self.tokenizer_name = 'microsoft/DialoGPT-small'\n",
        "        self.cache_dir = 'cached'\n",
        "        self.block_size = 512\n",
        "        self.do_train = True\n",
        "        self.do_eval = True\n",
        "        self.evaluate_during_training = False\n",
        "        self.per_gpu_train_batch_size = 4\n",
        "        self.per_gpu_eval_batch_size = 4\n",
        "        self.gradient_accumulation_steps = 1\n",
        "        self.learning_rate = 5e-5\n",
        "        self.weight_decay = 0.0\n",
        "        self.adam_epsilon = 1e-8\n",
        "        self.max_grad_norm = 1.0\n",
        "        self.num_train_epochs = 3\n",
        "        self.max_steps = -1\n",
        "        self.warmup_steps = 0\n",
        "        self.logging_steps = 1000\n",
        "        self.save_steps = 3500\n",
        "        self.save_total_limit = None\n",
        "        self.eval_all_checkpoints = False\n",
        "        self.no_cuda = False\n",
        "        self.overwrite_output_dir = True\n",
        "        self.overwrite_cache = True\n",
        "        self.should_continue = False\n",
        "        self.seed = 42\n",
        "        self.local_rank = -1\n",
        "        self.fp16 = False\n",
        "        self.fp16_opt_level = 'O1'\n",
        "\n",
        "args = Args()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xq9V0cST28N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}