{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import transformers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch import cuda\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('news-expand.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>summary</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Australian batsman Steve Smith reveals he near...</td>\n",
       "      <td>australia batsman steve smith has revealed tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>milind soman recently trekked to the highest p...</td>\n",
       "      <td>milind soman needs no introduction and nor doe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>singer Aditya Narayan shared a picture of hims...</td>\n",
       "      <td>ahead of his wedding (reportedly on december 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Rubina Dilaik will reveal one of the deepest s...</td>\n",
       "      <td>tv star rubina dilaik will reveal one of the d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>the couple, who got married exactly a month ag...</td>\n",
       "      <td>it is a happy day for kajal aggarwal and her h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            summary  \\\n",
       "0           0  Australian batsman Steve Smith reveals he near...   \n",
       "1           1  milind soman recently trekked to the highest p...   \n",
       "2           2  singer Aditya Narayan shared a picture of hims...   \n",
       "3           3  Rubina Dilaik will reveal one of the deepest s...   \n",
       "4           4  the couple, who got married exactly a month ag...   \n",
       "\n",
       "                                                text  \n",
       "0  australia batsman steve smith has revealed tha...  \n",
       "1  milind soman needs no introduction and nor doe...  \n",
       "2  ahead of his wedding (reportedly on december 1...  \n",
       "3  tv star rubina dilaik will reveal one of the d...  \n",
       "4  it is a happy day for kajal aggarwal and her h...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create CustomDataset class for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, dataframe, tokenizer, source_len, summ_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = dataframe\n",
    "        self.source_len = source_len\n",
    "        self.summ_len = summ_len\n",
    "        self.text = self.data.summary\n",
    "        self.ctext = self.data.text\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ctext = str(self.ctext[index])\n",
    "        ctext = ' '.join(ctext.split())\n",
    "\n",
    "        text = str(self.text[index])\n",
    "        text = ' '.join(text.split())\n",
    "\n",
    "        source = self.tokenizer.batch_encode_plus([ctext], max_length = self.source_len, padding = 'max_length',\\\n",
    "                                                  return_tensors = 'pt', truncation = True)\n",
    "        target = self.tokenizer.batch_encode_plus([text], max_length = self.summ_len, padding = 'max_length',\\\n",
    "                                                  return_tensors = 'pt', truncation = True)\n",
    "\n",
    "        source_ids = source['input_ids'].squeeze().to(dtype = torch.long)\n",
    "        source_mask = source['attention_mask'].squeeze().to(dtype = torch.long)\n",
    "        target_ids = target['input_ids'].squeeze().to(dtype = torch.long)\n",
    "        \n",
    "        y_ids = target_ids[:-1].contiguous() # make y_ids contiguous \n",
    "        lm_labels = target_ids[1:].clone().detach() # make fast copy\n",
    "        lm_labels[target_ids[1:] == tokenizer.pad_token_id] = -100 # replace pad tokens\n",
    "\n",
    "        return {\n",
    "            'input_ids': source_ids, \n",
    "            'attention_mask': source_mask, \n",
    "            'decoder_input_ids': y_ids,\n",
    "            'labels': lm_labels\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (8104, 2)\n",
      "TRAIN Dataset: (6483, 2)\n",
      "TEST Dataset: (1621, 2)\n"
     ]
    }
   ],
   "source": [
    "TRAIN_BATCH_SIZE = 2\n",
    "VALID_BATCH_SIZE = 2 \n",
    "TRAIN_EPOCHS = 25      \n",
    "VAL_EPOCHS = 1 \n",
    "LEARNING_RATE = 1e-4    \n",
    "SEED = 42               \n",
    "MAX_LEN = 512\n",
    "SUMMARY_LEN = 128\n",
    "\n",
    "torch.manual_seed(SEED) \n",
    "np.random.seed(SEED) \n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "\n",
    "df = df[['text','summary']]\n",
    "df.summary = 'summarize: ' + df.summary \n",
    "\n",
    "train_size = 0.8\n",
    "train_dataset = df.sample(frac=train_size,random_state = SEED)\n",
    "val_dataset = df.drop(train_dataset.index).reset_index(drop = True)\n",
    "train_dataset = train_dataset.reset_index(drop = True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(val_dataset.shape))\n",
    "\n",
    "training_set = CustomDataset(train_dataset, tokenizer, MAX_LEN, SUMMARY_LEN)\n",
    "val_set = CustomDataset(val_dataset, tokenizer, MAX_LEN, SUMMARY_LEN)\n",
    "\n",
    "train_params = {\n",
    "    'batch_size': TRAIN_BATCH_SIZE,\n",
    "    'shuffle': True,\n",
    "    'num_workers': 0\n",
    "    }\n",
    "\n",
    "val_params = {\n",
    "    'batch_size': VALID_BATCH_SIZE,\n",
    "    'shuffle': False,\n",
    "    'num_workers': 0\n",
    "    }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "val_loader = DataLoader(val_set, **val_params)\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-tt-trainer/\")\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(output_dir=\"t5-tt-trainer/\",\n",
    "                         seed=42,\n",
    "                         num_train_epochs=25,\n",
    "                         per_device_train_batch_size=2,  \n",
    "                         # max batch size without OOM exception, because of the large max token length\n",
    "                         per_device_eval_batch_size=2,\n",
    "                         logging_steps=2500,\n",
    "                         save_steps=0,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=training_set,\n",
    "    eval_dataset=val_set,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='81050' max='81050' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [81050/81050 3:08:17, Epoch 25/25]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.078000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.870900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.738600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.669300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.626700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.592900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.559300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>0.524300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.485200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>0.464600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.445600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>0.431300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.403900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37500</td>\n",
       "      <td>0.383400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.365800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42500</td>\n",
       "      <td>0.356400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>0.339000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47500</td>\n",
       "      <td>0.329200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.314800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52500</td>\n",
       "      <td>0.303200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>0.297800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57500</td>\n",
       "      <td>0.285000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.276000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62500</td>\n",
       "      <td>0.271900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>0.265800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67500</td>\n",
       "      <td>0.256400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>0.255600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72500</td>\n",
       "      <td>0.242900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>0.250700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77500</td>\n",
       "      <td>0.241700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>0.237000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=81050, training_loss=0.4333953317104483, metrics={'train_runtime': 11297.955, 'train_samples_per_second': 7.174, 'total_flos': 138511275291993600, 'epoch': 25.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(epoch, tokenizer, model, device, loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    texts = []\n",
    "    with torch.no_grad():\n",
    "        for _, data in tqdm(enumerate(loader, 0)):\n",
    "            y = data['decoder_input_ids'].to(device, dtype = torch.long)\n",
    "            ids = data['input_ids'].to(device, dtype = torch.long)\n",
    "            mask = data['attention_mask'].to(device, dtype = torch.long)\n",
    "\n",
    "            generated_ids = model.generate(\n",
    "                input_ids = ids,\n",
    "                attention_mask = mask, \n",
    "                max_length = 100, \n",
    "                num_beams = 2,\n",
    "                repetition_penalty = 2.5, \n",
    "                length_penalty = 1.0, \n",
    "                early_stopping = True\n",
    "                )\n",
    "            preds = [tokenizer.decode(g, skip_special_tokens = True, clean_up_tokenization_spaces = True)\\\n",
    "                     for g in generated_ids]\n",
    "            target = [tokenizer.decode(t, skip_special_tokens = True, clean_up_tokenization_spaces = True)\\\n",
    "                      for t in y]\n",
    "            text = [tokenizer.decode(i, skip_special_tokens = True, clean_up_tokenization_spaces = True)\\\n",
    "                      for i in ids]\n",
    "            if _%2500==0:\n",
    "                print(f'Completed {_}')\n",
    "\n",
    "            predictions.extend(preds)\n",
    "            actuals.extend(target)\n",
    "            texts.extend(text)\n",
    "    return predictions, actuals, texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"t5-tt-trainer/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "811it [23:47,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation took 1427.3927965164185 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for epoch in range(VAL_EPOCHS):\n",
    "    predictions, actuals, text = validate(epoch, tokenizer, model, device, val_loader)\n",
    "    final_df = pd.DataFrame({'Generated Text': predictions,'Actual Text': actuals, 'Text': text})\n",
    "print(\"Validation took \" + str(time.time() - start_time) + \" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out Generated vs Actual Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Generated Text</th>\n",
       "      <th>Actual Text</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>: bigg boss 14's star rubina dilaik will revea...</td>\n",
       "      <td>summarize: Rubina Dilaik will reveal one of th...</td>\n",
       "      <td>tv star rubina dilaik will reveal one of the d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kajal Aggarwal and her husband Gautam Kitchlu ...</td>\n",
       "      <td>summarize: the couple, who got married exactly...</td>\n",
       "      <td>it is a happy day for kajal aggarwal and her h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amitabh Bachchan's Instagram account is a shee...</td>\n",
       "      <td>summarize: Amitabh Bachchan's latest post is a...</td>\n",
       "      <td>there is absolutely no denying the fact that a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a twitter user addressed Karan Johar as \"the f...</td>\n",
       "      <td>summarize: a twitter user addressed Karan Joha...</td>\n",
       "      <td>karan johar, who is quite used to be being tro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>actress ankita Lokhande is all set to perform ...</td>\n",
       "      <td>summarize: ankita Lokhande is all set to perfo...</td>\n",
       "      <td>tv star ankita lokhande, who is all set to per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>: one day later de telegraaf, a daily amsterda...</td>\n",
       "      <td>summarize: but there are other positive uses o...</td>\n",
       "      <td>mobile picture power in your pocket how many t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>: a delta spokesperson confirmed on wednesday ...</td>\n",
       "      <td>summarize: a delta spokesperson confirmed on w...</td>\n",
       "      <td>us blogger fired by her airline a us airline a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>: clearswift said that fact that no viral code...</td>\n",
       "      <td>summarize: a windows virus called bofra is tur...</td>\n",
       "      <td>toxic web links help virus spread virus writer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>: the system is not available commercially yet...</td>\n",
       "      <td>summarize: the system is not available commerc...</td>\n",
       "      <td>mobile networks seek turbo boost third-generat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>: in a panel discussion at a linux summit in c...</td>\n",
       "      <td>summarize: in a panel discussion at a linux su...</td>\n",
       "      <td>open source leaders slam patents the war of wo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1621 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Generated Text  \\\n",
       "0     : bigg boss 14's star rubina dilaik will revea...   \n",
       "1     Kajal Aggarwal and her husband Gautam Kitchlu ...   \n",
       "2     amitabh Bachchan's Instagram account is a shee...   \n",
       "3     a twitter user addressed Karan Johar as \"the f...   \n",
       "4     actress ankita Lokhande is all set to perform ...   \n",
       "...                                                 ...   \n",
       "1616  : one day later de telegraaf, a daily amsterda...   \n",
       "1617  : a delta spokesperson confirmed on wednesday ...   \n",
       "1618  : clearswift said that fact that no viral code...   \n",
       "1619  : the system is not available commercially yet...   \n",
       "1620  : in a panel discussion at a linux summit in c...   \n",
       "\n",
       "                                            Actual Text  \\\n",
       "0     summarize: Rubina Dilaik will reveal one of th...   \n",
       "1     summarize: the couple, who got married exactly...   \n",
       "2     summarize: Amitabh Bachchan's latest post is a...   \n",
       "3     summarize: a twitter user addressed Karan Joha...   \n",
       "4     summarize: ankita Lokhande is all set to perfo...   \n",
       "...                                                 ...   \n",
       "1616  summarize: but there are other positive uses o...   \n",
       "1617  summarize: a delta spokesperson confirmed on w...   \n",
       "1618  summarize: a windows virus called bofra is tur...   \n",
       "1619  summarize: the system is not available commerc...   \n",
       "1620  summarize: in a panel discussion at a linux su...   \n",
       "\n",
       "                                                   Text  \n",
       "0     tv star rubina dilaik will reveal one of the d...  \n",
       "1     it is a happy day for kajal aggarwal and her h...  \n",
       "2     there is absolutely no denying the fact that a...  \n",
       "3     karan johar, who is quite used to be being tro...  \n",
       "4     tv star ankita lokhande, who is all set to per...  \n",
       "...                                                 ...  \n",
       "1616  mobile picture power in your pocket how many t...  \n",
       "1617  us blogger fired by her airline a us airline a...  \n",
       "1618  toxic web links help virus spread virus writer...  \n",
       "1619  mobile networks seek turbo boost third-generat...  \n",
       "1620  open source leaders slam patents the war of wo...  \n",
       "\n",
       "[1621 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('predsvsactual.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model in tensorflow to upload to huggingface model repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model = transformers.TFT5ForConditionalGeneration.from_pretrained(\"t5-tt-trainer/\", from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model.save_pretrained(\"t5-tt-trainer/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.T5Tokenizer.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained('./')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
