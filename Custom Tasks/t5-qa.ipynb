{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import logging\n",
    "import argparse\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level = logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 24 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv').dropna()\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "train, val = train_test_split(train, test_size=0.13, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment: negative tweet:  How did we just get paid and still be broke as hell?! No shopping spree for me today\n",
      "sentiment: positive tweet: i no i no bt i had only been a gamer for like 2 years when i made that attempt  lol yea i luvd F1 to an extent \n",
      "sentiment: positive tweet: I love when my ipod shuffles so all the good songs are all together\n",
      "sentiment: neutral tweet:  no i mean 2moz. I`m workin` 7-1 in a bakers then 6-4 later in a pub\n",
      "sentiment: positive tweet: Lovely walk this morning with the missus; drizzle didn`t matter\n",
      "sentiment: neutral tweet:  , just dont understand what`s it got to do with me. I`m just a nice girl\n",
      "sentiment: negative tweet: getting bored of walking up and down the stairs\n",
      "sentiment: positive tweet:  have your own style. it just might work.\n",
      "sentiment: negative tweet: fighting with mum on mothers day\n",
      "sentiment: neutral tweet:  & I got too much work to do\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "for a,b,_ in zip(train.sentiment.values[:10], train.text.values[:10], train.selected_text.values[:10]):\n",
    "    print(\"sentiment:\", a, \"tweet:\", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "broke as hell?!\n",
      "luvd\n",
      "love\n",
      "no i mean 2moz. I`m workin` 7-1 in a bakers then 6-4 later in a pub\n",
      "Lovely walk this morning with the missus; drizzle didn`t matter\n",
      ", just dont understand what`s it got to do with me. I`m just a nice girl\n",
      "getting bored of walking up and down the stairs\n",
      "it just might work.\n",
      "fighting\n",
      "I got too much work to do\n"
     ]
    }
   ],
   "source": [
    "# Target\n",
    "for _,_,c in zip(train.sentiment.values[:10], train.text.values[:10], train.selected_text.values[:10]):\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append EOS token to target text, This is the standard format for T5 targets\n",
    "train['selected_text'] = train['selected_text'] + ' </s>'\n",
    "val['selected_text'] = val['selected_text'] + ' </s>'\n",
    "\n",
    "# Apply Q&A structure\n",
    "# From Appendix D in the T5 paper\n",
    "processed_input_train = (\"question: \" + train.sentiment + \" context: \" + train.text)\n",
    "processed_input_test = (\"question: \" + test.sentiment + \" context: \" + test.text)\n",
    "processed_input_val = (\"question: \" + val.sentiment + \" context: \" + val.text)\n",
    "\n",
    "# Save data as string separated by \\n (new line)\n",
    "processed_input_str_train = '\\n'.join(processed_input_train.values.tolist())\n",
    "processed_input_str_test = '\\n'.join(processed_input_test.values.tolist())\n",
    "selected_text_str_train = '\\n'.join(train['selected_text'].values.tolist())\n",
    "processed_input_str_val = '\\n'.join(processed_input_val.values.tolist())\n",
    "selected_text_str_val = '\\n'.join(val['selected_text'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('question: neutral context:  I`d have responded, if I were going',\n",
       " 'I`d have responded, if I were going </s>')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_input_train[0], train['selected_text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'question: neutral context: Last session of the day  http://twitpic.com/67ezh'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_input_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.source', 'w') as f:\n",
    "    f.write(processed_input_str_train)\n",
    "\n",
    "with open('test.source', 'w') as f:\n",
    "    f.write(processed_input_str_test)\n",
    "    \n",
    "with open('val.source', 'w') as f:\n",
    "    f.write(processed_input_str_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.target', 'w') as f:\n",
    "    f.write(selected_text_str_train)\n",
    "    \n",
    "with open('val.target', 'w') as f:\n",
    "    f.write(selected_text_str_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
